{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1615754a-e12f-4fe2-ae64-575d450133d1",
   "metadata": {},
   "source": [
    "# Capse.jl chains\n",
    "In this notebook we will show how to use the Capse.jl emulator in combination with Turing.jl, performing a PlanckLite analysis. In particolar, we are gonna show:\n",
    "\n",
    "- How to compute the Maximum A Posteriori (MAP), using the L-BFGS method provided by Optim.jl\n",
    "- How to use Pathfinder.jl to obtain a quick posterior estimate and initialize chains\n",
    "- How to use NUTS and MicroCanonical Hamiltonian MonteCarlo as sampling algorithms\n",
    "\n",
    "Let us start initializing the Julia environment. This will download and install the precise version of the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n",
    "Pkg.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc147a0e-3648-4149-bdf2-584acbf98b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using SimpleChains\n",
    "using NPZ\n",
    "using Turing\n",
    "using Optim\n",
    "using Pathfinder\n",
    "using StatsPlots\n",
    "using Capse\n",
    "using BenchmarkTools\n",
    "using LinearAlgebra\n",
    "using NPZ\n",
    "using JSON\n",
    "using Transducers\n",
    "using PlanckLite\n",
    "import MCMCChains: compute_duration\n",
    "using MicroCanonicalHMC\n",
    "using MCMCDiagnosticTools\n",
    "using DataFrames\n",
    "using ForwardDiff\n",
    "include(\"utils.jl\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "081edd8d",
   "metadata": {},
   "source": [
    "Here we initialize the neural network we use for the emulator. This is done loading a dictionary, saved in a JSON file, that contains all the information required to instantiate the right NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650d8eb-098a-4d8b-a805-d3eab6d06a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_dict = JSON.parsefile(\"nn_setup.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61845769",
   "metadata": {},
   "source": [
    "If you wanna see some details about the NN we created, just use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c2a88-1000-4b69-bd9d-0d9a7835ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = \"../data/weights/weights_cosmopowerspace_10000/\"\n",
    "ℓ = npzread(weights_folder*\"l.npy\")\n",
    "\n",
    "weights_TT = npzread(weights_folder*\"weights_TT_lcdm.npy\")\n",
    "trained_emu_TT = Capse.init_emulator(NN_dict, weights_TT, Capse.SimpleChainsEmulator)\n",
    "CℓTT_emu = Capse.CℓEmulator(TrainedEmulator = trained_emu_TT, ℓgrid = ℓ,\n",
    "                             InMinMax = npzread(weights_folder*\"inMinMax_lcdm.npy\"),\n",
    "                             OutMinMax = npzread(weights_folder*\"outMinMaxCℓTT_lcdm.npy\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4a2b6",
   "metadata": {},
   "source": [
    "After creating the neural network, we initialize our emulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "Capse.get_emulator_description(CℓTT_emu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48462a",
   "metadata": {},
   "source": [
    "Let us benchmark `Capse.jl` against some random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbeba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(6)\n",
    "@benchmark Capse.get_Cℓ($x, $CℓTT_emu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32753f13-ce21-433e-be5d-61a7e683b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_EE = npzread(weights_folder*\"weights_EE_lcdm.npy\")\n",
    "trained_emu_EE = Capse.init_emulator(NN_dict, weights_EE, Capse.SimpleChainsEmulator)\n",
    "CℓEE_emu = Capse.CℓEmulator(TrainedEmulator = trained_emu_EE, ℓgrid = ℓ,\n",
    "                             InMinMax = npzread(weights_folder*\"inMinMax_lcdm.npy\"),\n",
    "                             OutMinMax = npzread(weights_folder*\"outMinMaxCℓEE_lcdm.npy\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1312a-c04d-431d-97ec-6694fc7b66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_TE = npzread(weights_folder*\"weights_TE_lcdm.npy\")\n",
    "trained_emu_TE = Capse.init_emulator(NN_dict, weights_TE, Capse.SimpleChainsEmulator)\n",
    "CℓTE_emu = Capse.CℓEmulator(TrainedEmulator = trained_emu_TE, ℓgrid = ℓ,\n",
    "                             InMinMax = npzread(weights_folder*\"inMinMax_lcdm.npy\"),\n",
    "                             OutMinMax = npzread(weights_folder*\"outMinMaxCℓTE_lcdm.npy\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7ed21-a18d-4bdf-b91d-279f036995d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_PP = npzread(weights_folder*\"weights_PP_lcdm.npy\")\n",
    "trained_emu_PP = Capse.init_emulator(NN_dict, weights_PP, Capse.SimpleChainsEmulator)\n",
    "CℓPP_emu = Capse.CℓEmulator(TrainedEmulator = trained_emu_PP, ℓgrid = ℓ,\n",
    "                             InMinMax = npzread(weights_folder*\"inMinMax_lcdm.npy\"),\n",
    "                             OutMinMax = npzread(weights_folder*\"outMinMaxCℓPP_lcdm.npy\"));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11ec7db2-ecfe-4cbb-b156-4298d3439af4",
   "metadata": {},
   "source": [
    "## PlanckLite & Turing\n",
    "\n",
    "Here we are going tyo create some functions to analyze Planck data.\n",
    "The first function, given a list of arguments, retrieves the binned $C_\\ell$'s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92be1a-ceb0-41f3-98e7-2b2a48f9c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsTT = 2:2508\n",
    "lsTE = 2:1996\n",
    "facTT=lsTT.*(lsTT.+1)./(2*π)\n",
    "facTE=lsTE.*(lsTE.+1)./(2*π)\n",
    "\n",
    "function call_emu_planck(θ, Emu_TT, Emu_TE, Emu_EE, facTT, facTE)\n",
    "    return PlanckLite.bin_Cℓ(Capse.get_Cℓ(θ, Emu_TT)[1:2507]./facTT,\n",
    "                            Capse.get_Cℓ(θ, Emu_TE)[1:1995]./facTE,\n",
    "                            Capse.get_Cℓ(θ, Emu_EE)[1:1995]./facTE)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7dc9d33",
   "metadata": {},
   "source": [
    "This other function is a closure, defining a more manageable version of the same function (in this way we don't have to pass some fixed arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5779b28-e515-4e1f-9469-f3b06298a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_planck(θ) = call_emu_planck(θ, CℓTT_emu, CℓTE_emu, CℓEE_emu, facTT, facTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark theory_planck($x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71e2d3a6",
   "metadata": {},
   "source": [
    "Since the Covariance matrix we are gonna use does not depend on the model parameters, we can define the following quantities\n",
    "\n",
    "$\\Gamma = \\mathrm{sqrt}(\\Lambda)$\n",
    "\n",
    "$i\\Gamma=\\mathrm{inv}(\\Gamma)$\n",
    "\n",
    "$D = i\\Gamma \\cdot d$\n",
    "\n",
    "We can now sample a MvNormal with an easier covariance matrix\n",
    "\n",
    "$D \\sim \\mathrm{MvNormal}(i\\Gamma\\cdot t(\\theta), I)$\n",
    "\n",
    "The advantage of this reparametrization is that we compute the inverse of a matrix just once and not at every step of the MCMC, without resoirting to any approximation: the two likelihood defined are mathematically equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9409394",
   "metadata": {},
   "outputs": [],
   "source": [
    "Γ = sqrt(PlanckLite.cov)\n",
    "iΓ = inv(Γ)\n",
    "D = iΓ * PlanckLite.data;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4907f63b",
   "metadata": {},
   "source": [
    "Although this is a bit different from the way we are used to code likelihoods in cosmology, it is easy to explain how to use a Probabilistic Programming Language (PPL) such as Turing.\n",
    "\n",
    "When we use the \"$\\sim$\" symbol, we are saying that the left-hand-side is sampled from the distribution on the right-hand-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4610bf8-320e-40f1-8889-2e6e306aa102",
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function CMB_planck(D, iΓ)\n",
    "    #prior on model parameters\n",
    "    ln10As ~ Uniform(0.25, 0.35)\n",
    "    ns     ~ Uniform(0.88, 1.06)\n",
    "    h0     ~ Uniform(0.60, 0.80)\n",
    "    ωb     ~ Uniform(0.1985, 0.25)\n",
    "    ωc     ~ Uniform(0.08, 0.20)\n",
    "    τ      ~ Normal(0.0506, 0.0086)\n",
    "    yₚ     ~ Normal(1.0, 0.0025)\n",
    "\n",
    "    θ = [10*ln10As, ns, 100*h0, ωb/10, ωc, τ]\n",
    "\n",
    "    #compute theoretical prediction\n",
    "    pred = iΓ * theory_planck(θ) ./(yₚ^2)\n",
    "    #compute likelihood\n",
    "    D ~ MvNormal(pred, I)\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "CMB_model_planck = CMB_planck(D, iΓ);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f843dbc",
   "metadata": {},
   "source": [
    "Let us perform the MAP computation. Turing has been interfaced with Optim, which provides some powerful minimization methods such as L-BFGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfit_Planck = optimize(CMB_model_planck, MAP(), Optim.Options(iterations=100000, allow_f_increases=true))\n",
    "@benchmark optimize(CMB_model_planck, MAP(), Optim.Options(iterations=100000, allow_f_increases=true))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0385f58",
   "metadata": {},
   "source": [
    "The minimization takes less than half a second!\n",
    "\n",
    "We are going to run 6 parallel chains, with 500 adaptation steps and 5'000 steps (note that Turing will not retrieve the burn-in steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f159a7-5d6c-43aa-8aa1-41ef4e41bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 5000\n",
    "nadapts = 500\n",
    "nchains = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "826ab2fa",
   "metadata": {},
   "source": [
    "Before starting chains, let us use Pathfinder. This will deliver an approximation to the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8f788-5865-41fc-a0b4-524763338142",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multi = multipathfinder(CMB_model_planck, 10000; nruns=8, executor=Transducers.PreferParallel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time multipathfinder(CMB_model_planck, 5000; nruns=8, executor=Transducers.PreferParallel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multi.draws_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_planck_PF = combine_chains(result_multi.draws_transformed)\n",
    "npzwrite(\"chains_Planck_PF.npy\", chain_planck_PF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c62e0ec",
   "metadata": {},
   "source": [
    "Pathfinder is incredibly fast: it performed the analysis in as few as 15 seconds. However, it is an approximate method. Although it might not always used to give a faithful approximation of the posteriori, it is very useful in starting the chains as close as possible to the typical set.\n",
    "\n",
    "Here we are gonna use some Pathfinder draws to initialize our chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af646cf-bc86-4fe4-a8d6-4c324c771e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = collect.(eachrow(result_multi.draws_transformed.value[1:nchains, :, 1]));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31be8320",
   "metadata": {},
   "source": [
    "Let us now start the NUTS chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_planck_nuts = sample(CMB_model_planck, NUTS(nadapts, 0.65), MCMCThreads(), nsteps, nchains; init_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18e9d0aa",
   "metadata": {},
   "source": [
    "Let us plot our chains. As we can see, the samples looks almost uncorrelated, which is consistent with our estimate of the correlation length, which is between 2-3 for cosmological parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d057e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = StatsPlots.plot(chains_planck_nuts)\n",
    "StatsPlots.savefig(\"traceplots_Planck.png\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9445ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_planck = combine_chains(chains_planck_nuts)\n",
    "npzwrite(\"chains_Planck_NUTS.npy\", chain_planck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92b68951",
   "metadata": {},
   "source": [
    "An interesting quantity we will compare with the MCHMC run is the ESS per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_s_Planck_NUTS = compute_duration(chains_planck_nuts)\n",
    "Planck_NUTS_ESS = mean(MCMCDiagnosticTools.ess_rhat(chains_planck_nuts)[[:ln10As, :ns, :h0, :ωb,:ωc, :τ, :yₚ],:ess])\n",
    "Planck_NUTS_ESS_s = Planck_NUTS_ESS/CPU_s_Planck_NUTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efc66c21",
   "metadata": {},
   "source": [
    "An ESS/s of 1.6 means that we can reach the (heuristic) threshold of 400 ESS in around 4 minutes and, taking advantage of the multiple processor, our analysis can be performed in around 1 minute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7612c1d7",
   "metadata": {},
   "source": [
    "## The MicroCanonical Hamiltonian MonteCarlo sampler\n",
    "Here we will use the Julia implementation of the MCHMC sampler.\n",
    "We will use 20'000 adaptation steps (that will be discarded) and 200'000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0666918",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 7\n",
    "target = TuringTarget(CMB_model_planck)\n",
    "nadapts = 20_000\n",
    "nsteps = 200_000\n",
    "spl = MCHMC(nadapts, 0.001; init_eps=0.05, L=sqrt(d),# sigma=ones(d),\n",
    "            adaptive=true)\n",
    "@time planck_mchmc = Sample(spl, target, nsteps;\n",
    "                       progress=true,\n",
    "                       dialog=true, file_name=\"chain_1\",\n",
    "                       initial_x=bestfit_Planck.values.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parallel_mchmc = 8\n",
    "chains = Vector{Any}(undef, n_parallel_mchmc)\n",
    "vec_ess = zeros(n_parallel_mchmc)\n",
    "\n",
    "nadapts = 20_000\n",
    "nsteps = 200_000\n",
    "start_mchmc = time()\n",
    "\n",
    "@time for i in 1:n_parallel_mchmc\n",
    "    chains[i] = Sample(MCHMC(nadapts, 0.001; init_eps=0.05, L=sqrt(d), adaptive=true), target, nsteps;\n",
    "                       progress=true,\n",
    "                       dialog=true, file_name=\"chain_1\",\n",
    "                       initial_x=bestfit_Planck.values.array)\n",
    "    vec_ess[i] = mean(Summarize(chains[i])[1][1:7])\n",
    "end\n",
    "\n",
    "end_mchmc = time()\n",
    "time_mchmc_parallel_Planck = end_mchmc - start_mchmc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eae8a69d",
   "metadata": {},
   "source": [
    "Let us compute the ESS per second of the parallel MCHMC run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Planck_MCHMC_parallel_ESS_s = sum(vec_ess)/time_mchmc_parallel_Planck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c1ce301",
   "metadata": {},
   "source": [
    "This is higher by a factor of 3 than the NUTS ESS/s!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f694ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "_chains = zeros(nsteps, n_parallel_mchmc, 7)\n",
    "for i in 1:n_parallel_mchmc\n",
    "    _chains[:,i,:] = mapreduce(permutedims, vcat, chains[i])[:,1:7]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mchmc = mapreduce(permutedims, vcat, planck_mchmc)\n",
    "E = planck_mchmc[:, end-1]\n",
    "std(E).^2/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [mapreduce(permutedims, vcat, chains[i]) for i in 1:n_parallel_mchmc]\n",
    "\n",
    "planck_mchmc_multi_chains = zeros(nsteps*n_parallel_mchmc, 7)\n",
    "for i in 1:7\n",
    "    planck_mchmc_multi_chains[:,i] = extract_single(x, i, n_parallel_mchmc)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzwrite(\"chains_Planck_MCHMC.npy\", planck_mchmc)\n",
    "npzwrite(\"chains_Planck_MCHMC_multi.npy\", planck_mchmc_multi_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13469150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nt 8 1.9.2",
   "language": "julia",
   "name": "nt-8-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
